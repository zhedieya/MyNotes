### intro

#### 从一道面试题开始讲起

> 从输入 URL 到页面加载完成，发生了什么？

我们现在站在性能优化的角度，一起简单地复习一遍这个经典的过程：首先我们需要通过 DNS（域名解析系统）将 URL 解析为对应的 IP 地址，然后与这个 IP 地址确定的那台服务器建立起 TCP 网络连接，随后我们向服务端抛出我们的 HTTP 请求，服务端处理完我们的请求之后，把目标数据放在 HTTP 响应里返回给客户端，拿到响应数据的浏览器就可以开始走一个渲染的流程。渲染完毕，页面便呈现给了用户，并时刻等待响应用户的操作（如下图所示）。

<img src="https://p1-jj.byteimg.com/tos-cn-i-t2oaga2asx/gold-user-assets/2018/10/18/16685737b823244c~tplv-t2oaga2asx-zoom-in-crop-mark:3024:0:0:0.awebp" alt="img" style="zoom:70%;" />

主要有以下过程：

1. DNS 解析
2. TCP 连接
3. HTTP 请求抛出
4. 服务端处理请求，HTTP 响应返回
5. 浏览器拿到响应数据，解析响应内容，把解析的结果展示给用户

#### 从原理到实践：各个击破

接下来要做的事情，就是针对这五个过程进行分解，各个提问，各个击破。

具体来说，**DNS** 解析花时间，能不能尽量减少解析次数或者把解析前置？能——浏览器 DNS 缓存和 DNS prefetch。

**TCP** 每次的三次握手都急死人，有没有解决方案？有——长连接、预连接、接入 SPDY 协议。

如果说这两个过程的优化往往需要我们和团队的服务端工程师协作完成，前端单方面可以做的努力有限，那么 **HTTP** 请求呢？——在减少请求次数和减小请求体积方面，我们应该是专家！

再者，服务器越远，一次请求就越慢，那部署时就把静态资源放在离我们更近的 **CDN** 上是不是就能更快一些？(网络层面)

以上提到的都是网络层面的性能优化。再往下走就是浏览器端的性能优化——这部分涉及资源加载优化、服务端渲染、浏览器缓存机制的利用、DOM 树的构建、网页排版和渲染过程、回流与重绘的考量、DOM 操作的合理规避等等(渲染层面)

整个的知识图谱，用思维导图展示如下：

<img src="https://p1-jj.byteimg.com/tos-cn-i-t2oaga2asx/gold-user-assets/2018/10/23/1669f5358f63c0f8~tplv-t2oaga2asx-zoom-in-crop-mark:3024:0:0:0.awebp" alt="img" style="zoom:30%;" />

### webpack 性能调优与 Gzip 原理

#### webpack 的性能瓶颈

相信每个用过 webpack 的同学都对“打包”和“压缩”这样的事情烂熟于心。这些老生常谈的特性，我更推荐大家去阅读文档。而关于 webpack 的详细操作，则推荐大家读读这本 [关于 webpack 的掘金小册](https://juejin.im/book/6844733709808041992/section/6844733709845790734#heading-2)，这里我们把注意力放在 webpack 的性能优化上。

webpack 的优化瓶颈，主要是两个方面：

- webpack 的构建过程太花时间
- webpack 打包的结果体积太大

#### webpack 优化方案

##### 构建过程提速策略

**不要让 loader 做太多事情——以 babel-loader 为例**

> 注：Babel 是现代 JavaScript 语法转换器(如**转译 esnext、typescript 等到目标环境支持的 js**)
>
> - 解析: 将代码(其实就是字符串)转换成 AST( 抽象语法树)
> - 转换: 访问 AST 的节点进行变换操作生成新的 AST
> - 生成: 以新的 AST 为基础生成代码

babel-loader 无疑是强大的，但它也是慢的。

最常见的优化方式是，用 include 或 exclude 来帮我们避免不必要的转译，比如 webpack 官方在介绍 babel-loader 时给出的示例：

```javascript
module: {
  rules: [
    {
      test: /\.js$/,
      exclude: /(node_modules|bower_components)/,
      use: {
        loader: 'babel-loader',
        options: {
          presets: ['@babel/preset-env']
        }
      }
    }
  ]
}
```

这段代码帮我们规避了对庞大的 node_modules 文件夹或者 bower_components 文件夹的处理。但通过限定文件范围带来的性能提升是有限的。除此之外，如果我们选择开启缓存将转译结果缓存至文件系统，则至少可以将 babel-loader 的工作效率提升两倍。要做到这点，我们只需要为 loader 增加相应的参数设定：

```javascript
loader: 'babel-loader?cacheDirectory=true'
```

尽管我们可以在 loader 配置时通过写入 exclude 去避免 babel-loader 对不必要的文件的处理，但是考虑到这个规则仅作用于这个 loader，像一些类似 UglifyJsPlugin 的 webpack 插件在工作时依然会被这些庞大的第三方库拖累，webpack 构建速度依然会因此大打折扣。所以针对这些庞大的第三方库，我们还需要做一些额外的努力。